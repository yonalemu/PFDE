{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'20220728_TRR_LSTM_FD'\n",
    "depth = r'All_Depth'\n",
    "\n",
    "model = r'LSTM'\n",
    "trained_on = 'All'\n",
    "k = 1 #Cluster Number\n",
    "\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "date_time_string = str(now.year) + str(now.month).zfill(2) + str(now.day).zfill(2) + \"_\" + str(now.hour).zfill(2) + str(now.minute).zfill(2) + str(now.second).zfill(2)\n",
    "date_processed = date_time_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Training\\Models'\n",
    "results_folder = r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Training\\Results'\n",
    "pred_results_folder =  r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries Loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import datetime\n",
    "import numpy as np\n",
    "import random as rn\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Concatenate, SimpleRNN, Masking, Flatten\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import os\n",
    "import xlwt \n",
    "from xlwt import Workbook \n",
    "from prettytable import PrettyTable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow.keras.backend as K\n",
    "import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Activation, BatchNormalization\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "print('Libraries Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(X, time_steps, ts_range):\n",
    "    '''\n",
    "    Returns the prepared data based on the lag and look ahead\n",
    "    \n",
    "    Parameters:\n",
    "        X          (float): The independent variables of the data\n",
    "        y          (float): The dependent variables of the data\n",
    "        time_steps (int)  : The lag that is being used to lookback\n",
    "        ts_range   (int)  : The lookahead for the data\n",
    "    \n",
    "    Returns:\n",
    "        Xs (float) : The numpy array of the input variable\n",
    "        ys (float) : The numpy array of the output variable \n",
    "    '''\n",
    "    Xs = []\n",
    "    for i in range(len(X) - time_steps - ts_range):\n",
    "        v = X.iloc[i:(i + time_steps),0:-1].values\n",
    "        Xs.append(v)\n",
    "        \n",
    "    return np.array(Xs)\n",
    "\n",
    "def splitter(df, features, output, lag,duration):\n",
    "    '''\n",
    "    Returns the training and testing data\n",
    "    \n",
    "    Parameters:\n",
    "        df (float): The whole dataframe containing the independent and dependent variables\n",
    "        output(str): The output variable \n",
    "        lag (int): The lag that needs to be applied for the data\n",
    "        duration (int): The duration that is being considered as output\n",
    "        ts (float): The percentage of training data\n",
    "    \n",
    "    Returns:\n",
    "        x_train (float): The training data of independent variable \n",
    "        x_test (float): The testing data of independent variable\n",
    "        y_train (float): The training data of the depenedent variable \n",
    "        y_test (float): The testing data of the dependent variable \n",
    "    '''\n",
    "    \n",
    "\n",
    "    pred_size = int(len(df))\n",
    "    pred = df.iloc[0:pred_size]\n",
    "    df_pred = pred.copy(deep=True)\n",
    "    x_pred = create_dataset(df_pred[features],lag,duration)\n",
    "\n",
    "    return x_pred\n",
    "\n",
    "\n",
    "\n",
    "class attention(keras.layers.Layer):\n",
    "    '''\n",
    "    Attention layer for the neural networks.\n",
    "    \n",
    "    if return_sequences=True, it will give 3D vector and if false it will give 2D vector. It is same as LSTMs.\n",
    "\n",
    "    https://stackoverflow.com/questions/62948332/how-to-add-attention-layer-to-a-bi-lstm/62949137#62949137\n",
    "    the  following code is being inspired from the above link.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, return_sequences=True, **kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention, self).__init__()\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        return cfg\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "\n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x * a\n",
    "\n",
    "        if self.return_sequences:\n",
    "            return output\n",
    "\n",
    "        return K.sum(output, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = r'NYJ'\n",
    "\n",
    "src = r'C:\\Users\\w10\\Desktop\\TRR\\TRR Compiled Data'\n",
    "\n",
    "prediction_csv_filename = r'NYJ.csv'\n",
    "\n",
    "predicting_df = pandas.read_csv(os.path.join(src,prediction_csv_filename), engine='python').fillna(0)\n",
    "predicting_dataset = predicting_df.values\n",
    "\n",
    "\n",
    "## Specifying the destination path\n",
    "dest = results_folder\n",
    "pred_dest = pred_results_folder\n",
    "features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3','RF', 'Wind_Speed', 'Humidity','Solar_Radiation', 'Snow','0mm','100mm','500mm','800mm','1100mm']\n",
    "\n",
    "prediction = predicting_df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = 6\n",
    "n_ahead = 1\n",
    "\n",
    "all_training_features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3', '0mm']\n",
    "\n",
    "d0mm_training_features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3',\n",
    "                          'RF', 'Wind_Speed', 'Humidity','Solar_Radiation', 'Snow','0mm']\n",
    "\n",
    "d100mm_training_features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3',\n",
    "                          'RF', 'Wind_Speed', 'Humidity','Solar_Radiation', 'Snow','100mm']\n",
    "\n",
    "d500mm_training_features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3',\n",
    "                          'RF', 'Wind_Speed', 'Humidity','Solar_Radiation', 'Snow','500mm']\n",
    "\n",
    "d800mm_training_features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3',\n",
    "                          'RF', 'Wind_Speed', 'Humidity','Solar_Radiation', 'Snow','800mm']\n",
    "\n",
    "d1100mm_training_features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3',\n",
    "                          'RF', 'Wind_Speed', 'Humidity','Solar_Radiation', 'Snow','1100mm']\n",
    "\n",
    "\n",
    "x_features = ['Air_Temperature', 'LPF_1', 'LPF_2', 'LPF_3','RF','Wind_Speed', 'Humidity','Solar_Radiation', 'Snow']\n",
    "\n",
    "\n",
    "d0mm_y_features = ['0mm']\n",
    "d100mm_y_features = ['100mm']\n",
    "d500mm_y_features = ['500mm']\n",
    "d800mm_y_features = ['800mm']\n",
    "d1100mm_y_features = ['1100mm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the matrices for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the training and testing data\n",
    "x_test_0mm= splitter(predicting_df,d0mm_training_features,'0mm',lag,1)\n",
    "x_test_100mm = splitter(predicting_df,d100mm_training_features,'100mm',lag,1)\n",
    "x_test_500mm= splitter(predicting_df,d500mm_training_features,'500mm',lag,1)\n",
    "x_test_800mm= splitter(predicting_df,d800mm_training_features,'800mm',lag,1)\n",
    "x_test_1100mm= splitter(predicting_df,d1100mm_training_features,'1100mm',lag,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 64\n",
    "lr = 0.0001\n",
    "n_layer = 32\n",
    "if lag ==1:\n",
    "    ker_size = 1\n",
    "else:\n",
    "    ker_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "486/486 [==============================] - 2s 2ms/step\n",
      "486/486 [==============================] - 2s 2ms/step\n",
      "486/486 [==============================] - 2s 2ms/step\n",
      "486/486 [==============================] - 2s 2ms/step\n",
      "486/486 [==============================] - 2s 2ms/step\n",
      "Prediction Complete\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "    lstm = keras.Sequential()\n",
    "    lstm.add(keras.layers.LSTM(n_layer, return_sequences=True, input_shape=(x_test_0mm.shape[1], x_test_0mm.shape[2])))\n",
    "    lstm.add(keras.layers.LSTM(n_layer, return_sequences=True))\n",
    "    lstm.add(keras.layers.Flatten())\n",
    "    lstm.add(keras.layers.Dense(32))\n",
    "    lstm.add(keras.layers.Dense(1))\n",
    "    return lstm\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "d0mm_model_path = r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Training\\Models\\20220729_034243_ChunCheon_20220728_TRR_LSTM_FD_0mm.hdf5'\n",
    "d100mm_model_path = r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Training\\Models\\20220729_034312_ChunCheon_20220728_TRR_LSTM_FD_100mm.hdf5'\n",
    "d500mm_model_path = r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Training\\Models\\20220729_034402_ChunCheon_20220728_TRR_LSTM_FD_500mm.hdf5'\n",
    "d800mm_model_path = r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Training\\Models\\20220729_034428_ChunCheon_20220728_TRR_LSTM_FD_800mm.hdf5'\n",
    "d1100mm_model_path = r'C:\\Users\\w10\\Desktop\\TRR\\Final Codes\\Freezing Depth\\Training\\Models\\20220729_034449_ChunCheon_20220728_TRR_LSTM_FD_1100mm.hdf5'\n",
    "    \n",
    "    \n",
    "# model = load_model(filepath_attention)\n",
    "def load_trained_model(path):\n",
    "    model = create_model()\n",
    "    model.load_weights(path)\n",
    "    return model\n",
    "\n",
    "d0mm_final_model = load_trained_model(d0mm_model_path)\n",
    "d100mm_final_model = load_trained_model(d100mm_model_path)\n",
    "d500mm_final_model = load_trained_model(d500mm_model_path)\n",
    "d800mm_final_model = load_trained_model(d800mm_model_path)\n",
    "d1100mm_final_model = load_trained_model(d1100mm_model_path)\n",
    "\n",
    "\n",
    "d0mm_preds = d0mm_final_model.predict(x_test_0mm)\n",
    "d100mm_preds = d100mm_final_model.predict(x_test_100mm)\n",
    "d500mm_preds = d500mm_final_model.predict(x_test_500mm)\n",
    "d800mm_preds = d800mm_final_model.predict(x_test_800mm)\n",
    "d1100mm_preds = d1100mm_final_model.predict(x_test_1100mm)\n",
    "\n",
    "print('Prediction Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual_0mm = predicting_df['0mm']\n",
    "y_actual_100mm = predicting_df['100mm']\n",
    "y_actual_500mm = predicting_df['500mm']\n",
    "y_actual_800mm = predicting_df['800mm']\n",
    "y_actual_1100mm = predicting_df['1100mm']\n",
    "\n",
    "days = pd.DataFrame(predicting_df['Date'].values[-len(d0mm_preds):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0mm = pd.DataFrame([x[0] for x in d0mm_preds])\n",
    "\n",
    "y_pred_100mm = pd.DataFrame([x[0] for x in d100mm_preds])\n",
    "\n",
    "y_pred_500mm = pd.DataFrame([x[0] for x in d500mm_preds])\n",
    "\n",
    "y_pred_800mm = pd.DataFrame([x[0] for x in d800mm_preds])\n",
    "\n",
    "y_pred_1100mm = pd.DataFrame([x[0] for x in d1100mm_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_frame = pd.concat([days, y_actual_0mm, y_pred_0mm,y_actual_100mm, y_pred_100mm,y_actual_500mm, y_pred_500mm,\n",
    "                       y_actual_800mm, y_pred_800mm,y_actual_1100mm, y_pred_1100mm,], axis = 1)\n",
    "test_frame.columns = ['Date', 'Actual_0mm', 'Predicted_0mm','Actual_100mm', 'Predicted_100mm','Actual_500mm', 'Predicted_500mm',\n",
    "                     'Actual_800mm', 'Predicted_800mm','Actual_1100mm', 'Predicted_1100mm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9250421524047852\n",
      "-2.174933910369873\n",
      "-0.7172691226005554\n",
      "0.2624317407608032\n",
      "0.463062047958374\n"
     ]
    }
   ],
   "source": [
    "min_temp_difference_0mm = test_frame.Actual_0mm.dropna().min()- test_frame.Predicted_0mm.dropna().min()\n",
    "min_temp_difference_100mm = test_frame.Actual_100mm.dropna().min()- test_frame.Predicted_100mm.dropna().min()\n",
    "min_temp_difference_500mm = test_frame.Actual_500mm.dropna().min()- test_frame.Predicted_500mm.dropna().min()\n",
    "min_temp_difference_800mm = test_frame.Actual_800mm.dropna().min()- test_frame.Predicted_800mm.dropna().min()\n",
    "min_temp_difference_1100mm = test_frame.Actual_1100mm.dropna().min()- test_frame.Predicted_1100mm.dropna().min()\n",
    "\n",
    "print(min_temp_difference_0mm)\n",
    "print(min_temp_difference_100mm)\n",
    "print(min_temp_difference_500mm)\n",
    "print(min_temp_difference_800mm)\n",
    "print(min_temp_difference_1100mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0mm Predicted Minimum Temperature: -11.425042152404785\n",
      "0mm Actual Minimum Temperature: -10.5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "100mm Predicted Minimum Temperature: -5.825066089630127\n",
      "100mm Actual Minimum Temperature: -8.0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "500mm Predicted Minimum Temperature: -0.2827308773994446\n",
      "500mm Actual Minimum Temperature: -1.0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "800mm Predicted Minimum Temperature: 1.2375682592391968\n",
      "800mm Actual Minimum Temperature: 1.5\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "1100mm Predicted Minimum Temperature: 2.536937952041626\n",
      "1100mm Actual Minimum Temperature: 3.0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "print(f'0mm Predicted Minimum Temperature: {test_frame.Predicted_0mm.dropna().min()}')\n",
    "print(f'0mm Actual Minimum Temperature: {test_frame.Actual_0mm.dropna().min()}')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "print(f'100mm Predicted Minimum Temperature: {test_frame.Predicted_100mm.dropna().min()}')\n",
    "print(f'100mm Actual Minimum Temperature: {test_frame.Actual_100mm.dropna().min()}')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "print(f'500mm Predicted Minimum Temperature: {test_frame.Predicted_500mm.dropna().min()}')\n",
    "print(f'500mm Actual Minimum Temperature: {test_frame.Actual_500mm.dropna().min()}')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "print(f'800mm Predicted Minimum Temperature: {test_frame.Predicted_800mm.dropna().min()}')\n",
    "print(f'800mm Actual Minimum Temperature: {test_frame.Actual_800mm.dropna().min()}')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "print(f'1100mm Predicted Minimum Temperature: {test_frame.Predicted_1100mm.dropna().min()}')\n",
    "print(f'1100mm Actual Minimum Temperature: {test_frame.Actual_1100mm.dropna().min()}')\n",
    "print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
